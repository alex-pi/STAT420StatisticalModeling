---
title: 'Week 6 - Midterm Assignment: A Simulation Project'
author: "STAT 420, Summer 2021,Alejandro Pimentel (ap41)"
date: ''
output:
  html_document: 
    theme: readable
    toc: yes  
    code_folding: show
  pdf_document: default
urlcolor: cyan
editor_options: 
  chunk_output_type: console
---

```{css, echo=FALSE}
p, li, td {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
```

# Simulation Study 2: Using RMSE for Selection?

## Introduction

In this simulation study we will investigate how well RMSE can be used to select the “best” model. Since splitting the data is random, we don’t expect it to work correctly each time. We could get unlucky. But averaged over many attempts, we should expect it to select the appropriate model.

We will simulate from the model

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \beta_5 x_{i5} + \beta_6 x_{i6} + \epsilon_i
\]

where $\epsilon_i \sim N(0, \sigma^2)$ and

- $\beta_0 = 0$,
- $\beta_1 = 3$,
- $\beta_2 = -4$,
- $\beta_3 = 1.6$,
- $\beta_4 = -1.1$,
- $\beta_5 = 0.7$,
- $\beta_6 = 0.5$.

We will consider a sample size of $500$ and three possible levels of noise. That is, three values of $\sigma$.

- $n = 500$
- $\sigma \in (1, 2, 4)$

We will use the data found in [`study_2.csv`](study_2.csv) for the values of the predictors. These should be kept constant for the entirety of this study. The `y` values in this data are a blank placeholder.

Each time we simulate the data, we randomly split the data into train and test sets of equal sizes (250 observations for training, 250 observations for testing).

For each, we fit **nine** models, with forms:

- `y ~ x1`
- `y ~ x1 + x2`
- `y ~ x1 + x2 + x3`
- `y ~ x1 + x2 + x3 + x4`
- `y ~ x1 + x2 + x3 + x4 + x5`
- `y ~ x1 + x2 + x3 + x4 + x5 + x6`, the correct form of the model as noted above
- `y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7`
- `y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8`
- `y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9`

For each model, calculate Train and Test RMSE.

\[
\text{RMSE}(\text{model, data}) = \sqrt{\frac{1}{n} \sum_{i = 1}^{n}(y_i - \hat{y}_i)^2}
\]

**Methods**

Read the `csv` file with our samples and take a look to some of them.

```{r message=FALSE, warning=FALSE}
library(readr)
study2_data <- read_csv("./study_2.csv")

head(study2_data)

```

```{r}
# Set a seed to have a stable generation of random numbers
birthday = 19820426
set.seed(birthday)
```

We start by defining a few functions to help with the overall simulation. Namely with the tasks:

- Calculate the RMSE.
- Generate simulation data.
- Get the RMSE values and minimums for each of the `9` models.

```{r}
rmse <- function(expected, predicted) {
  n <- length(expected)
  sqrt(sum((expected - predicted)^2) / n)
}

# Generate the simulation data, concretely the y values given an epsilon
# and the known model with 6 predictors.
simulate_data <- function(X, betas, sigma) {
  n <- nrow(X)
  #print(X[, 2:7])
  epsilon <- rnorm(n = n, mean = 0, sd = sigma)
  X_full <- as.matrix(cbind(1, X[, 2:7]))
  X$y <- (X_full %*% betas) + epsilon
  as.data.frame(X)
}

# This function calculates the RMSE for train an test data as well
# as the index of the minimum RMSE on each case.
collect_rmse <- function(trn_data, tst_data) {
  rmse_matrix <- matrix(-1, 2, 9)

  for(im in 1:9) {
    trn_mod <- trn_data[, 1:(im+1)]
    tst_mod <- tst_data[, 1:(im+1)]
    sim_model <- lm(y ~ ., data = trn_mod)
    rmse_matrix[1, im] <- rmse(trn_mod$y, sim_model$fitted.values)
    tst_predictions <- predict(sim_model, newdata = tst_mod)
    rmse_matrix[2, im] <- rmse(tst_mod$y, tst_predictions)
  }
  list(
    rmse_matrix = rmse_matrix,
    trn_min_idx = which.min(rmse_matrix[1, ]),
    tst_min_idx = which.min(rmse_matrix[2, ])
    )
}

```

Next, we pre-allocate variables we will use during the simulation.

```{r}
betas <- matrix(c(0, 3, -4, 1.6, -1.1, 0.7, 0.5))
sigma1 <- 1
sigma2 <- 2
sigma4 <- 4
num_sims <- 10

rmse_s1_acc <- matrix(0, 2, 9)
rmse_s2_acc <- matrix(0, 2, 9)
rmse_s4_acc <- matrix(0, 2, 9)

which_mins_s1 <- matrix(0, 2, num_sims)
which_mins_s2 <- matrix(0, 2, num_sims)
which_mins_s4 <- matrix(0, 2, num_sims)

```

The loop below runs the simulation and collects all the data. As described in the introduction: 

Each time we simulate the data, we randomly split the data into `train` and `test` sets of equal sizes (250 observations for training, 250 observations for testing).

Then for each model, we calculate Train and Test RMSE.

```{r}
# The main loop with num_sims simulations

for(i in 1:num_sims) {

  # We simulate the data for the known model (with 7 betas).
  # For each sigma we get a different data set.
  data_sigma1 <- simulate_data(study2_data, betas, sigma1)
  data_sigma2 <- simulate_data(study2_data, betas, sigma2)
  data_sigma4 <- simulate_data(study2_data, betas, sigma4)
  
  # Get 250 random indexes for observations
  idxs <- 1:nrow(study2_data)
  trn_idx = sample(idxs, 250)
  #print(trn_idx)
  
  # Training splits for each sigma
  data_sigma1_trn <- data_sigma1[trn_idx, ]
  data_sigma2_trn <- data_sigma2[trn_idx, ]
  data_sigma4_trn <- data_sigma4[trn_idx, ]
  
  # Testing splits for each sigma
  data_sigma1_tst <- data_sigma1[!(idxs %in% trn_idx), ]
  data_sigma2_tst <- data_sigma2[!(idxs %in% trn_idx), ]
  data_sigma4_tst <- data_sigma4[!(idxs %in% trn_idx), ]
  
  # We get a list with test and train RMSE and the index with 
  # then min RMSE for both cases
  rmse_sigma1 <- collect_rmse(data_sigma1_trn, data_sigma1_tst)
  rmse_sigma2 <- collect_rmse(data_sigma2_trn, data_sigma2_tst)
  rmse_sigma4 <- collect_rmse(data_sigma4_trn, data_sigma4_tst)
  
  # Accumulate the rmse in a 2 by 9 matrix, 
  # we'll use it for the average
  rmse_s1_acc <- rmse_s1_acc + rmse_sigma1$rmse_matrix
  rmse_s2_acc <- rmse_s2_acc + rmse_sigma2$rmse_matrix
  rmse_s4_acc <- rmse_s4_acc + rmse_sigma4$rmse_matrix
  
  # Allocate the index of the minimum RMSE for test/train and each sigma
  which_mins_s1[1, i] <- rmse_sigma1$trn_min_idx
  which_mins_s1[2, i] <- rmse_sigma1$tst_min_idx
  
  which_mins_s2[1, i] <- rmse_sigma2$trn_min_idx
  which_mins_s2[2, i] <- rmse_sigma2$tst_min_idx
  
  which_mins_s4[1, i] <- rmse_sigma4$trn_min_idx
  which_mins_s4[2, i] <- rmse_sigma4$tst_min_idx  

}


```

```{r fig.height = 6, fig.width = 10, fig.align = "center"}
line_plot <- function(y1, y2, sigma, title) {
  plot(1:9, y1,
       xlab = "Model size (number of predictors)", 
       ylab = paste("Average RMSE (", num_sims, "simulations )"),
       main = paste(title," ( sigma =", sigma,")"),     
       col = "darkorange",
       lwd=2.5,
       lty=2,
       col.main='blue',
       type='o')
  
  lines(1:9,y2,
        lwd=2.5,
        lty=3,        
        col='cadetblue3',
        type='o')
  
  legend("topright", c("Train", "Test"), 
       lty = c(2, 3),
       lwd = 3,
       col = c("darkorange", "cadetblue3"))  
}


par(mfrow=c(1, 3), bg="ghostwhite")
t <- "Avg. RMSE vs Model Size"
line_plot(rmse_s1_acc[1, ] / num_sims, rmse_s1_acc[2, ] / num_sims,
          sigma = 1, title = t)
line_plot(rmse_s2_acc[1, ] / num_sims, rmse_s2_acc[2, ] / num_sims,
          sigma = 2, title = t)
line_plot(rmse_s4_acc[1, ] / num_sims, rmse_s4_acc[2, ] / num_sims,
          sigma = 4, title = t)
```

