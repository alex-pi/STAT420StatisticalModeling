}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
# Chunk 19
par(mfrow = c(1, 1), bg="ghostwhite")
hist(Credit$Income, breaks = 20,
xlab = "Income values",
border = "gray80",
col = "deepskyblue3"
)
# Chunk 20
(add_balance_mod <- lm(Balance ~ . - Income + log(Income)
, data = Credit))
(small_balance_mod <- step(add_balance_mod, direction = "backward"
, trace = 0, k = log(nrow(Credit))))
# Chunk 21
mod_a <- lm(Balance ~ Limit
+ poly(Cards, degree = 3)
+ poly(Age, degree = 2)
+ Student + log(Income)
, data = Credit)
# Chunk 22
get_loocv_rmse(mod_a)
get_adj_r2(mod_a)
get_bp_decision(mod_a, alpha = 0.01)
get_num_params(mod_a)
# Chunk 23
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
# Chunk 24
mod_b_big <- lm(Balance ~ (Limit +
+ Cards
+ Age
+ Student
+ Married
+ Education
+ log(Income)) ^ 2
, data = Credit)
mod_b <- step(mod_b_big,
direction = "backward"
, trace = 0)
diags <- diagnostics(mod_b,
detailed = TRUE, plotit = TRUE)
# Chunk 25
get_loocv_rmse(mod_b)
get_adj_r2(mod_b)
get_sw_decision(mod_b, alpha = 0.01)
get_num_params(mod_b)
# Chunk 26
library(caret)
library(ggplot2)
data(Sacramento)
sac_data = Sacramento
sac_data$limits = factor(ifelse(sac_data$city == "SACRAMENTO", "in", "out"))
sac_data = subset(sac_data, select = -c(city, zip))
# Chunk 27
qplot(y = longitude, x = latitude, data = sac_data,
col = limits, main = "Sacramento City Limits ")
# Chunk 28
set.seed(420)
sac_trn_idx  = sample(nrow(sac_data), size = trunc(0.80 * nrow(sac_data)))
sac_trn_data = sac_data[sac_trn_idx, ]
sac_tst_data = sac_data[-sac_trn_idx, ]
# Chunk 29
#pairs(sac_trn_data)
big_price_mod <- lm(price ~ (
+ sqft + I(sqft^2)
+ beds
+ baths
+ latitude
+ longitude
+ limits
+ type
) ^ 2
, data = sac_trn_data)
bic_price_mod <- step(big_price_mod
,direction = "backward"
,k = log(nrow(sac_trn_data))
,trace = 0)
get_loocv_rmse(bic_price_mod)
# Chunk 30
predicted <- predict(bic_price_mod, newdata = sac_tst_data)
actual <- sac_tst_data$price
(avg_perct_error <- mean(abs(predicted - actual) / predicted) * 100)
# Chunk 31
par(mfrow = c(1, 1), bg="ghostwhite")
plot(predicted, actual,
col = "grey", pch = 20,
xlab = "Predicted Prices", ylab = "Actual Prices",
main = "Fitted vs Residuals")
abline(0, 1, col = "darkorange", lwd = 2)
# Chunk 32
beta_0  = 1
beta_1  = -1
beta_2  = 2
beta_3  = -2
beta_4  = 1
beta_5  = 1
beta_6  = 0
beta_7  = 0
beta_8  = 0
beta_9  = 0
beta_10 = 0
sigma = 2
# Chunk 33
not_sig  = c("x_6", "x_7", "x_8", "x_9", "x_10")
signif = c("x_1", "x_2", "x_3", "x_4", "x_5")
# Chunk 34
set.seed(420)
n = 100
x_1  = runif(n, 0, 10)
x_2  = runif(n, 0, 10)
x_3  = runif(n, 0, 10)
x_4  = runif(n, 0, 10)
x_5  = runif(n, 0, 10)
x_6  = runif(n, 0, 10)
x_7  = runif(n, 0, 10)
x_8  = runif(n, 0, 10)
x_9  = runif(n, 0, 10)
x_10 = runif(n, 0, 10)
# Chunk 35
sim_data_1 = data.frame(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10,
y = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 +
beta_5 * x_5 + rnorm(n, 0 , sigma)
)
# Chunk 36
head(sim_data_1)
# Chunk 37
fit = lm(y ~ x_1 + x_2 + x_6 + x_7, data = sim_data_1)
coef(fit)
# Chunk 38
# which are false negatives?
!(signif %in% names(coef(fit)))
# Chunk 39
# which are false positives?
names(coef(fit)) %in% not_sig
# Chunk 40
birthday = 19820426
set.seed(birthday)
X <- sim_data_1[, 1:10]
betas <- c(1, -1, 2, -2, 1, 1, rep(0, 5))
num_sims <- 300
# Chunk 41
generate_mlr_data <- function(X, betas, sigma = 2) {
n <- nrow(X)
epsilon <- rnorm(n = n, mean = 0, sd = sigma)
X_full <- as.matrix(cbind(1, X))
X$y <- (X_full %*% betas) + epsilon
as.data.frame(X)
}
get_fn_fp <- function(model, sim_data) {
aic_coef_names <- names(step(model, direction = "backward",
trace = 0)$coef)
bic_coef_names <- names(step(model, direction = "backward",
k = log(n), trace = 0)$coef)
r <- list(
aic_fn = sum(!(signif %in% aic_coef_names)),
aic_fp = sum(aic_coef_names %in% not_sig),
bic_fn = sum(!(signif %in% bic_coef_names)),
bic_fp = sum(bic_coef_names %in% not_sig)
)
#print("-------")
#print(aic_coef_names)
#print(paste(r$aic_fn, r$aic_fp))
#print(bic_coef_names)
#print(paste(r$bic_fn, r$bic_fp))
#print("-------")
r
}
# Chunk 42
run_sim <- function(X, betas, sigma) {
#run_sim1 <- function() {
fn_count <- c(0, 0)
fp_count <- c(0, 0)
for(i in 1:num_sims) {
sim_data <- generate_mlr_data(X, matrix(betas), sigma)
sim_model <- lm(y ~ ., data = sim_data)
stats <- get_fn_fp(sim_model, sim_data)
fn_count[1] <- stats$aic_fn + fn_count[1]
fn_count[2] <- stats$bic_fn + fn_count[2]
fp_count[1] <- stats$aic_fp + fp_count[1]
fp_count[2] <- stats$bic_fp + fp_count[2]
}
list(fn = fn_count, fp = fp_count)
}
result_sim <- run_sim(X, betas, sigma)
#result_sim <- run_sim1()
# Chunk 43
tdata <- data.frame(
"fn" = result_sim$fn,
"fp" = result_sim$fp,
"fn_rate" = result_sim$fn / (num_sims * 5),
"fp_rate" = result_sim$fp / (num_sims * 5)
)
gen_kable(tdata, row_names = c("AIC", "BIC"),
col_names = c("False Negatives", "False Positives",
"FN Rate", "FP Rate"))
# Chunk 44
set.seed(94)
x_1  = runif(n, 0, 10)
x_2  = runif(n, 0, 10)
x_3  = runif(n, 0, 10)
x_4  = runif(n, 0, 10)
x_5  = runif(n, 0, 10)
x_6  = runif(n, 0, 10)
x_7  = runif(n, 0, 10)
x_8  = x_1 + rnorm(n, 0, 0.1)
x_9  = x_1 + rnorm(n, 0, 0.1)
x_10 = x_2 + rnorm(n, 0, 0.1)
sim_data_2 = data.frame(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10,
y = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 +
beta_5 * x_5 + rnorm(n, 0 , sigma)
)
birthday = 19820426
set.seed(birthday)
X <- sim_data_2[, 1:10]
betas <- c(1, -1, 2, -2, 1, 1, rep(0, 5))
num_sims <- 300
round(cor(X), 3)
cor_matrix <- round(cor(X), 3)
cor_matrix[1, 8]
cor_matrix <- round(cor(X), 4)
cor_matrix[1, 10]
cor_matrix <- round(cor(X), 4)
cor_matrix
cor_matrix[1, 10]
cor_matrix[1, 8]
cor_matrix[2, 10]
# Get the correlation matrix and setting 0 in the diagonal
cor(longley)
mod_1b_coefs
mod_1b_coefs[, 4]
mod_1b_coefs[, 4] < alpha
anova_1f
bic_price_mod
summary(bic_price_mod)
summary(bic_price_mod)$r.squared
tdata <- data.frame(
"fn" = result_sim$fn,
"fp" = result_sim$fp,
"fn_rate" = result_sim$fn / num_sims,
"fp_rate" = result_sim$fp / num_sims
)
gen_kable(tdata, row_names = c("AIC", "BIC"),
col_names = c("False Negatives", "False Positives",
"FN Rate", "FP Rate"),
caption = "Predictor picks (Backward BIC)")
# Chunk 1
p, li, td {
font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
# Chunk 2
library(knitr)
library(kableExtra)
library(dplyr)
library(lmtest)
gen_kable <- function(table_data, add_row_names = TRUE, caption = "", col_names = c(), row_names = c()) {
#f_data <- format_numerics(table_data)
f_data <- table_data
if(length(col_names) != 0){
colnames(f_data) <- col_names
}
if(length(row_names) != 0){
rownames(f_data) <- row_names
}
f_data %>%
kable(., format = "html", row.names = add_row_names,
caption = caption, escape = FALSE) %>%
kable_styling(bootstrap_options = c("striped", "hover"),
full_width = F,
font_size = 14,
position = "center")
}
stat_decide <- function(p_f_value, alpha = 0.01) {
ifelse(p_f_value < alpha, "Reject the Null Hypothesis", "FTR the Null Hypothesis")
}
diagnostics <- function(model, pcol = "grey", lcol = "dodgerblue",
alpha = 0.05, plotit = TRUE, testit = TRUE,
detailed = FALSE) {
diags <- NULL
if(testit) {
p_val_st <- shapiro.test(model$residuals)$p.value
p_val_bp <- bptest(model)$p.value
hval <- hatvalues(model)
cookd <- cooks.distance(model)
diags <- list(
"p_val" = p_val_st,
"decision" = ifelse(p_val_st < alpha, "Reject", "Fail to Reject")
)
# Extending the function to add more diagnostics
if(detailed) {
diags$leverage <- list(
"values" = hval,
"large" = hval > 2 * mean(hval))
diags$bptest <- list(
"p_val" = p_val_bp,
"decision" = ifelse(p_val_bp < alpha, "Reject", "Fail to Reject"))
diags$cookd <- list(
"values" = cookd,
"influential" = cookd[cookd > 4 / length(cookd)])
}
}
if(plotit) {
par(mfrow = c(1, 2), bg="ghostwhite")
plot(model$fitted.values, model$residuals,
col = pcol, pch = 20,
xlab = "Fitted", ylab = "Residuals",
main = "Fitted vs Residuals")
abline(h = 0, col = lcol, lwd = 2)
qqnorm(model$residuals, main = "Normal Q-Q Plot",
col = pcol)
qqline(model$residuals, col = lcol, lwd = 2)
}
diags
}
# Chunk 3: setup
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
# Chunk 5
# Get the correlation matrix and setting 0 in the diagonal
cor(longley)
cor_0_on_diag <- cor(longley) * !diag(ncol(longley))
max_cor_val <- max(cor_0_on_diag)
pred_names <- row.names(which(cor_0_on_diag == max_cor_val, arr.ind = TRUE))
# Chunk 6
library(faraway)
mod_1b <- lm(Employed ~ ., data = longley)
(longley_vif <- vif(mod_1b))
max_vif <- longley_vif[longley_vif==max(longley_vif)]
large_vif_preds <- names(longley_vif > 5)
# Chunk 7
mod_1c <- lm(Population ~ . - Employed, data = longley)
popu_r2 <- summary(mod_1c)$r.squared
# Chunk 8
mod_1d_no_pop <- lm(Employed ~ . - Population, data = longley)
(pcres_emp_pop <- cor(mod_1c$residuals, mod_1d_no_pop$residuals))
# Chunk 9
mod_1b_coefs <- summary(mod_1b)$coef
alpha <- 0.05
# Select the coefficients that are lower than 0.05
(signif_coefs <- mod_1b_coefs[mod_1b_coefs[, 4] < alpha, ])
# Chunk 10
mod_1e <- lm(Employed ~ Unemployed + Armed.Forces + Year, data = longley)
(longley_vif <- vif(mod_1e))
max_vif <- longley_vif[longley_vif==max(longley_vif)]
# Chunk 11
anova_1f <- anova(mod_1e, mod_1b)
f_stat <- anova_1f[2, "F"]
p_val <- anova_1f[2, "Pr(>F)"]
df1 <- anova_1f[2, "Df"]
df2 <- anova_1f[2, "Res.Df"]
# Chunk 12
(stat_decision <- stat_decide(p_val, alpha))
# Chunk 13
(pref_mod <- mod_1e)
# Chunk 14
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
plot(fitted(model), resid(model),
col = pointcol, pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals",
main = "Fitted vs Residuals")
abline(h = 0, col = linecol, lwd = 2)
}
plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
qqline(resid(model), col = linecol, lwd = 2)
}
# Chunk 15
par(mfrow = c(1, 2), bg="ghostwhite")
plot_fitted_resid(pref_mod)
plot_qq(pref_mod)
# Chunk 16
diags <- diagnostics(pref_mod, detailed = TRUE, plotit = FALSE)
p_val_bp <- diags$bptest$p_val
p_val_sha <- diags$p_val
# Chunk 17
library(ISLR)
data(Credit)
Credit = subset(Credit, select = -c(ID))
# Chunk 18
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
# Chunk 19
par(mfrow = c(1, 1), bg="ghostwhite")
hist(Credit$Income, breaks = 20,
xlab = "Income values",
border = "gray80",
col = "deepskyblue3"
)
# Chunk 20
(add_balance_mod <- lm(Balance ~ . - Income + log(Income)
, data = Credit))
(small_balance_mod <- step(add_balance_mod, direction = "backward"
, trace = 0, k = log(nrow(Credit))))
# Chunk 21
mod_a <- lm(Balance ~ Limit
+ poly(Cards, degree = 3)
+ poly(Age, degree = 2)
+ Student + log(Income)
, data = Credit)
# Chunk 22
get_loocv_rmse(mod_a)
get_adj_r2(mod_a)
get_bp_decision(mod_a, alpha = 0.01)
get_num_params(mod_a)
# Chunk 23
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
# Chunk 24
mod_b_big <- lm(Balance ~ (Limit +
+ Cards
+ Age
+ Student
+ Married
+ Education
+ log(Income)) ^ 2
, data = Credit)
mod_b <- step(mod_b_big,
direction = "backward"
, trace = 0)
# Chunk 25
get_loocv_rmse(mod_b)
get_adj_r2(mod_b)
get_sw_decision(mod_b, alpha = 0.01)
get_num_params(mod_b)
# Chunk 26
library(caret)
library(ggplot2)
data(Sacramento)
sac_data = Sacramento
sac_data$limits = factor(ifelse(sac_data$city == "SACRAMENTO", "in", "out"))
sac_data = subset(sac_data, select = -c(city, zip))
# Chunk 27
qplot(y = longitude, x = latitude, data = sac_data,
col = limits, main = "Sacramento City Limits ")
# Chunk 28
set.seed(420)
sac_trn_idx  = sample(nrow(sac_data), size = trunc(0.80 * nrow(sac_data)))
sac_trn_data = sac_data[sac_trn_idx, ]
sac_tst_data = sac_data[-sac_trn_idx, ]
# Chunk 29
#pairs(sac_trn_data)
big_price_mod <- lm(price ~ (
+ sqft + I(sqft^2)
+ beds
+ baths
+ latitude
+ longitude
+ limits
+ type
) ^ 2
, data = sac_trn_data)
# Using BIC backward search
bic_price_mod <- step(big_price_mod
,direction = "backward"
,k = log(nrow(sac_trn_data))
,trace = 0)
get_loocv_rmse(bic_price_mod)
# Chunk 30
predicted <- predict(bic_price_mod, newdata = sac_tst_data)
actual <- sac_tst_data$price
(avg_perct_error <- mean(abs(predicted - actual) / predicted) * 100)
summary(bic_price_mod)
summary(bic_price_mod)$r.squared
